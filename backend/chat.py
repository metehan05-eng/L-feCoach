from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from sqlalchemy.future import select
import sys
import os
sys.path.append(os.path.dirname(__file__))

from auth import get_current_user
from database import async_session, User, ChatHistory
import logging
from datetime import datetime, timezone, timedelta
import httpx
from dotenv import load_dotenv

load_dotenv()
logging.basicConfig(level=logging.INFO)
# Read Gemini configuration
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

class ChatMessage(BaseModel):
    message: str
    feature: str = "chat"


router = APIRouter()

async def get_user_data(email: str):
    """Get user data from database"""
    try:
        async with async_session() as session:
            result = await session.execute(select(User).where(User.email == email))
            user = result.scalar_one_or_none()
            if user:
                return {
                    "user_type": "free",
                    "language": user.language or "tr",
                    "message_count": user.message_count or 0,
                    "last_message_date": user.last_message_date
                }
        return {"user_type": "free", "language": "tr", "message_count": 0, "last_message_date": None}
    except Exception as e:
        logging.error(f"Error getting user data: {str(e)}")
        return {"user_type": "free", "language": "tr", "message_count": 0, "last_message_date": None}

def check_message_limit(user_data: dict) -> tuple[bool, int]:
    """Check if user can send message and return remaining messages"""
    return True, -1  # Unlimited for all users

async def reset_message_count_if_needed(email: str, user_data: dict) -> bool:
    """Reset message count if cooldown period has passed. Returns True if reset occurred."""
    last_message_date = user_data.get("last_message_date")
    if not last_message_date:
        return False

    try:
        last_message_time = datetime.fromisoformat(last_message_date.replace('Z', '+00:00'))
        current_time = datetime.now(timezone.utc)
        cooldown_period = timedelta(hours=5)

        if current_time - last_message_time >= cooldown_period:
            # Reset count
            async with async_session() as session:
                result = await session.execute(select(User).where(User.email == email))
                user = result.scalar_one_or_none()
                if user:
                    user.message_count = 0
                    user.last_message_date = None
                    await session.commit()
                    user_data["message_count"] = 0
                    user_data["last_message_date"] = None
                    return True
    except Exception as e:
        logging.error(f"Error resetting message count: {e}")

    return False

async def update_message_count(email: str, user_data: dict):
    """Update user's message count"""
    now = datetime.now(timezone.utc).isoformat()
    new_count = user_data["message_count"] + 1

    try:
        async with async_session() as session:
            result = await session.execute(select(User).where(User.email == email))
            user = result.scalar_one_or_none()
            if user:
                user.message_count = new_count
                user.last_message_date = now
                await session.commit()
    except Exception as e:
        logging.error(f"Error updating message count: {str(e)}")

@router.post("/chat")
async def chat(message: ChatMessage, current_user: str = Depends(get_current_user)):
    try:
        # Get user data
        user_data = await get_user_data(current_user)
        
        # Try Ollama local server first (if available). Otherwise use built-in fallbacks.
        msg = message.message.lower()

        async def call_gemini(prompt: str) -> str | None:
            """Call Google Gemini API for AI response."""
            if not GEMINI_API_KEY:
                return None

            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
            headers = {"Content-Type": "application/json"}
            payload = {
                "contents": [{"parts": [{"text": prompt}]}]
            }

            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    resp = await client.post(url, headers=headers, json=payload)
                    if resp.status_code != 200:
                        logging.debug(f"Gemini API returned status {resp.status_code}: {resp.text}")
                        return None

                    data = resp.json()
                    if "candidates" in data and len(data["candidates"]) > 0:
                        candidate = data["candidates"][0]
                        if "content" in candidate and "parts" in candidate["content"]:
                            parts = candidate["content"]["parts"]
                            if len(parts) > 0 and "text" in parts[0]:
                                return parts[0]["text"].strip()

            except Exception as e:
                logging.debug(f"Gemini call failed: {e}")

            return None

        # Try Gemini and use its response if it's meaningful (not just echo)
        try:
            gemini_text = await call_gemini(message.message)
            if gemini_text:
                gemini_text = gemini_text.strip()
                if gemini_text and gemini_text.lower() != message.message.lower():
                    ai_response = gemini_text
                    response_payload = {"text": ai_response, "source": "gemini", "model": "gemini-1.5-flash"}

                    # Save history and return
                    async with async_session() as session:
                        new_chat = ChatHistory(
                            user_email=current_user,
                            message=message.message,
                            response=response_payload["text"],
                            feature=message.feature,
                            created_at=datetime.now(timezone.utc)
                        )
                        session.add(new_chat)
                        await session.commit()

                    return {"response": response_payload, "remaining_messages": -1}
        except Exception:
            logging.debug("Ollama inference attempt raised an exception; continuing with fallback.")
        
        # Intelligent Turkish responses based on keywords
        if "merhaba" in msg or "selam" in msg or "hey" in msg or "hi" in msg:
            ai_response = "Merhaba! NasÄ±lsÄ±n bugÃ¼n? HayatÄ±nda sana nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ˜Š"
        elif "yardÄ±m" in msg or "nasÄ±l" in msg:
            ai_response = "Size motivasyon, hedef belirleme, duygusal destek veya gÃ¼nlÃ¼k tutma konusunda yardÄ±mcÄ± olabilirim. Ne hakkÄ±nda konuÅŸmak istersiniz?"
        elif "hedef" in msg or "amaÃ§" in msg or "plan" in msg:
            ai_response = "Harika! Hedef belirlemek baÅŸarÄ±nÄ±n ilk adÄ±mÄ±dÄ±r. SMART hedefler (Spesifik, Ã–lÃ§Ã¼lebilir, EriÅŸilebilir, Ä°lgili, ZamanlÄ±) oluÅŸturmanÄ±za yardÄ±mcÄ± olabilirim. Ne tÃ¼r bir hedef belirlemek istiyorsunuz?"
        elif "duygu" in msg or "Ã¼zgÃ¼n" in msg or "mutlu" in msg or "kÃ¶tÃ¼" in msg or "iyi" in msg:
            ai_response = "DuygularÄ±nÄ±zÄ± paylaÅŸmak cesaret ister ve Ã§ok deÄŸerlidir. Bu duygularÄ± anlamanÄ±za ve yÃ¶netmenize yardÄ±mcÄ± olabilirim. Åu an ne hissediyorsunuz?"
        elif "motivasyon" in msg or "enerji" in msg or "isteksiz" in msg:
            ai_response = "Motivasyon bazen dalgalanabilir, bu Ã§ok normal. Size motivasyonunuzu artÄ±racak stratejiler ve teknikler Ã¶nerebilirim. Hangi alanda kendinizi daha motive hissetmek istiyorsunuz?"
        elif "stres" in msg or "kaygÄ±" in msg or "endiÅŸe" in msg:
            ai_response = "Stres ve kaygÄ± modern hayatÄ±n bir parÃ§asÄ±. Bunlarla baÅŸa Ã§Ä±kmanÄ±za yardÄ±mcÄ± olacak teknikler Ã¶ÄŸretebilirim. Sizi en Ã§ok ne strese sokuyor?"
        elif "baÅŸarÄ±" in msg or "kazanmak" in msg or "baÅŸarmak" in msg:
            ai_response = "BaÅŸarÄ± yolculuÄŸu kÃ¼Ã§Ã¼k adÄ±mlarla baÅŸlar. Size baÅŸarÄ±ya ulaÅŸmanÄ±z iÃ§in bir yol haritasÄ± Ã§izebilirim. Hangi alanda baÅŸarÄ±lÄ± olmak istiyorsunuz?"
        elif "teÅŸekkÃ¼r" in msg or "saÄŸol" in msg or "teÅŸekkÃ¼rler" in msg:
            ai_response = "Rica ederim! Size yardÄ±mcÄ± olmaktan mutluluk duyuyorum. BaÅŸka bir konuda yardÄ±mcÄ± olabilir miyim? ğŸ˜Š"
        elif "gÃ¼naydÄ±n" in msg:
            ai_response = "GÃ¼naydÄ±n! Yeni bir gÃ¼n, yeni fÄ±rsatlar demek. BugÃ¼n kendiniz iÃ§in ne yapmak istersiniz?"
        elif "iyi geceler" in msg or "hoÅŸÃ§akal" in msg or "gÃ¶rÃ¼ÅŸÃ¼rÃ¼z" in msg:
            ai_response = "Ä°yi geceler! YarÄ±n yeni bir gÃ¼n olacak. Kendinize iyi bakÄ±n! ğŸŒ™"
        elif "kim" in msg and ("sen" in msg or "siz" in msg):
            ai_response = "Ben bir yapay zeka yaÅŸam koÃ§uyum. Sizin kiÅŸisel geliÅŸiminize, hedeflerinize ulaÅŸmanÄ±za ve daha mutlu bir hayat sÃ¼rmenize yardÄ±mcÄ± olmak iÃ§in buradayÄ±m."
        elif "nasÄ±lsÄ±n" in msg or "nasÄ±lsÄ±nÄ±z" in msg:
            ai_response = "Ben iyiyim, teÅŸekkÃ¼r ederim! Sizinle konuÅŸmaktan mutluluk duyuyorum. Siz nasÄ±lsÄ±nÄ±z?"
        else:
            ai_response = "AnlÄ±yorum. Bu konuda daha fazla detay verebilir misiniz? Size en iyi ÅŸekilde yardÄ±mcÄ± olmak istiyorum. ğŸ’­"

        response_payload = {
            "text": ai_response,
            "source": "lifecoach-ai",
            "model": "built-in",
        }

        # Save chat history
        async with async_session() as session:
            new_chat = ChatHistory(
                user_email=current_user,
                message=message.message,
                response=response_payload["text"],
                feature=message.feature,
                created_at=datetime.now(timezone.utc)
            )
            session.add(new_chat)
            await session.commit()

        return {
            "response": response_payload,
            "remaining_messages": -1
        }

    except Exception as e:
        logging.error(f"Chat error: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router.get("/chat/history")
async def get_chat_history(current_user: str = Depends(get_current_user)):
    try:
        async with async_session() as session:
            result = await session.execute(
                select(ChatHistory).where(ChatHistory.user_email == current_user).order_by(ChatHistory.created_at)
            )
            chats = result.scalars().all()
            return [{"message": c.message, "response": c.response, "created_at": c.created_at.isoformat()} for c in chats]
    except Exception as e:
        logging.error(f"History error: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")